{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0cfa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yangh\\OneDrive\\Documents\\BaselineModel\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc0158",
   "metadata": {},
   "source": [
    "Load data as well as split into loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1d9579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clean train → tensors: 100%|██████████| 7329/7329 [08:58<00:00, 13.62 examples/s]  \n",
      "corrupt train → tensors: 100%|██████████| 7329/7329 [08:54<00:00, 13.71 examples/s]  \n",
      "val → tensors: 100%|██████████| 815/815 [01:12<00:00, 11.18 examples/s] \n",
      "test → tensors: 100%|██████████| 8041/8041 [11:21<00:00, 11.81 examples/s]  \n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"tanganke/stanford_cars\")        # {train, test}\n",
    "\n",
    "split = ds[\"train\"].train_test_split(test_size=0.10,\n",
    "                                     stratify_by_column=\"label\",\n",
    "                                     seed=42)\n",
    "ds[\"train\"], ds[\"val\"] = split[\"train\"], split[\"test\"]\n",
    "\n",
    "# base preprocessing\n",
    "base = v2.Compose([\n",
    "    v2.Resize((224, 224), antialias=True),\n",
    "    v2.ToImage(),\n",
    "    v2.ConvertImageDtype(torch.float32),\n",
    "    v2.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# corruption pool (always applied)\n",
    "corruption_pool = v2.RandomChoice([\n",
    "    v2.GaussianBlur(kernel_size=(15,15), sigma=(8,8)),\n",
    "    v2.RandomAdjustSharpness(sharpness_factor=2.5),\n",
    "    v2.RandomAutocontrast(),\n",
    "    v2.RandomEqualize(),\n",
    "    v2.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
    "    v2.RandomInvert(p=1.0),\n",
    "    v2.RandomSolarize(threshold=0.3, p=1.0),\n",
    "])\n",
    "\n",
    "train_transform      = v2.Compose([base, corruption_pool])   # always corrupt\n",
    "val_test_transform   = base                                  # keep clean\n",
    "\n",
    "def apply_tf(example, tf):\n",
    "    example[\"pixel_values\"] = tf(example[\"image\"].convert(\"RGB\"))\n",
    "    return example\n",
    "\n",
    "#MATERIALISE \n",
    "\n",
    "\n",
    "ds[\"train_clean\"]   = ds[\"train\"].map(apply_tf, fn_kwargs={\"tf\": val_test_transform},\n",
    "                                      desc=\"clean train → tensors\")\n",
    "ds[\"train_corrupt\"] = ds[\"train\"].map(apply_tf, fn_kwargs={\"tf\": train_transform},\n",
    "                                      desc=\"corrupt train → tensors\")\n",
    "ds[\"val\"]  = ds[\"val\"].map(apply_tf,  fn_kwargs={\"tf\": val_test_transform},\n",
    "                           desc=\"val → tensors\")\n",
    "ds[\"test\"] = ds[\"test\"].map(apply_tf, fn_kwargs={\"tf\": val_test_transform},\n",
    "                           desc=\"test → tensors\")\n",
    "\n",
    "# keep only needed columns\n",
    "for split in (\"train_clean\",\"train_corrupt\",\"val\",\"test\"):\n",
    "    ds[split].set_format(type=\"torch\", columns=[\"pixel_values\",\"label\"])\n",
    "\n",
    "#CONCAT clean+corrupt for training\n",
    "train_all = ConcatDataset([ds[\"train_clean\"], ds[\"train_corrupt\"]])\n",
    "\n",
    "#  DATALOADERS\n",
    "BATCH = 32\n",
    "train_loader = DataLoader(train_all, batch_size=BATCH, shuffle=True,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(ds[\"val\"],   batch_size=BATCH, shuffle=True,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(ds[\"test\"],  batch_size=BATCH, shuffle=True,\n",
    "                          num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c452d1",
   "metadata": {},
   "source": [
    "Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16618774",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)   # pretrained=True\n",
    "model.fc = nn.Linear(model.fc.in_features, 196)            # 196 classes\n",
    "model.to(device)\n",
    "\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "optimizer  = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfea0650",
   "metadata": {},
   "source": [
    "Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f328ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/10 ─ Train L 3.6161  Acc 25.59%   Val L 1.9263  Acc 49.57%\n",
      "Epoch  2/10 ─ Train L 1.3296  Acc 70.94%   Val L 1.0712  Acc 71.90%\n",
      "Epoch  3/10 ─ Train L 0.4818  Acc 90.35%   Val L 0.8995  Acc 74.97%\n",
      "Epoch  4/10 ─ Train L 0.1894  Acc 96.83%   Val L 0.8608  Acc 77.30%\n",
      "Epoch  5/10 ─ Train L 0.1071  Acc 98.40%   Val L 0.8288  Acc 76.32%\n",
      "Epoch  6/10 ─ Train L 0.0782  Acc 98.81%   Val L 0.8159  Acc 77.55%\n",
      "Epoch  7/10 ─ Train L 0.0933  Acc 98.29%   Val L 1.1577  Acc 72.02%\n",
      "Epoch  8/10 ─ Train L 0.1285  Acc 97.28%   Val L 0.9978  Acc 74.72%\n",
      "Epoch  9/10 ─ Train L 0.0810  Acc 98.24%   Val L 0.9749  Acc 76.20%\n",
      "Epoch 10/10 ─ Train L 0.0771  Acc 98.38%   Val L 1.0069  Acc 75.34%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "tr_loss_hist, tr_acc_hist = [], []\n",
    "va_loss_hist, va_acc_hist = [], []\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    # training \n",
    "    model.train()\n",
    "    run_loss = correct = total = 0\n",
    "    for batch in train_loader:\n",
    "        x = batch[\"pixel_values\"].to(device, non_blocking=True)\n",
    "        y = batch[\"label\"].to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        out   = model(x)\n",
    "        loss  = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        run_loss += loss.item()\n",
    "        total    += y.size(0)\n",
    "        correct  += out.argmax(1).eq(y).sum().item()\n",
    "\n",
    "    tr_loss = run_loss / len(train_loader)\n",
    "    tr_acc  = 100 * correct / total\n",
    "    tr_loss_hist.append(tr_loss)\n",
    "    tr_acc_hist.append(tr_acc)\n",
    "\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    val_loss = val_correct = val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x = batch[\"pixel_values\"].to(device, non_blocking=True)\n",
    "            y = batch[\"label\"].to(device, non_blocking=True)\n",
    "            out = model(x)\n",
    "            val_loss   += criterion(out, y).item()\n",
    "            val_total  += y.size(0)\n",
    "            val_correct += out.argmax(1).eq(y).sum().item()\n",
    "\n",
    "    va_loss = val_loss / len(val_loader)\n",
    "    va_acc  = 100 * val_correct / val_total\n",
    "    va_loss_hist.append(va_loss)\n",
    "    va_acc_hist.append(va_acc)\n",
    "\n",
    "    print(f\"Epoch {ep:2d}/{EPOCHS} ─ \"\n",
    "          f\"Train L {tr_loss:.4f}  Acc {tr_acc:5.2f}%   \"\n",
    "          f\"Val L {va_loss:.4f}  Acc {va_acc:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed7a07",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a369495",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplt\u001b[49m.figure()\n\u001b[32m      2\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, EPOCHS + \u001b[32m1\u001b[39m), tr_acc_hist, label=\u001b[33m\"\u001b[39m\u001b[33mTrain Acc\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, EPOCHS + \u001b[32m1\u001b[39m), va_acc_hist, label=\u001b[33m\"\u001b[39m\u001b[33mVal Acc\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1, EPOCHS + 1), tr_acc_hist, label=\"Train Acc\")\n",
    "plt.plot(range(1, EPOCHS + 1), va_acc_hist, label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy (%)\"); plt.title(\"Accuracy Curves\")\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca03543",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b2a20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 74.44%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_correct = test_total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x = batch[\"pixel_values\"].to(device, non_blocking=True)\n",
    "        y = batch[\"label\"].to(device, non_blocking=True)\n",
    "        out = model(x)\n",
    "        test_total   += y.size(0)\n",
    "        test_correct += out.argmax(1).eq(y).sum().item()\n",
    "\n",
    "print(f\"\\nTest Accuracy: {100 * test_correct / test_total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99da1787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to runs\\resnet_aug3\\checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "run_name  = \"resnet_aug3\"                 # pick any tag\n",
    "save_dir  = Path(\"runs\") / run_name\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    \"epoch\": EPOCHS,\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer_state\": optimizer.state_dict(),   # optional\n",
    "    \"val_acc\": va_acc_hist[-1],                  # optional\n",
    "}, save_dir / \"checkpoint.pt\")\n",
    "print(\"Saved to\", save_dir / \"checkpoint.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
